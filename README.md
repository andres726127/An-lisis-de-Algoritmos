## Nombre: Leonardo Mendieta
### Nota: Los talleres se encuentran en el apartado de Wiki!

# Introducci√≥n

Este libro es sobre algoritmos, o sea, esas instrucciones que te dicen c√≥mo hacer cosas paso a paso. Al principio aclaramos qu√© carajo significa eso y mostramos varias formas simples de hacer multiplicaciones para que se entienda bien. Adem√°s, te damos la raz√≥n por la que estudiar algoritmos no es solo √∫til, sino que tambi√©n puede ser interesante (aunque a veces parezca un embole).

Si ten√©s olvidadas las matem√°ticas b√°sicas o los conceptos de computaci√≥n, no te asustes: ac√° vas a encontrar un repaso r√°pido con lo m√°s importante. No vamos a dar clases de c√°lculo o programaci√≥n, pero s√≠ lo b√°sico para que sigas el libro sin perderte.

## ¬øQu√© es un algoritmo?

Un algoritmo es b√°sicamente un conjunto de reglas para hacer un c√°lculo o resolver un problema, ya sea con l√°piz y papel o en una compu. Lo que hacemos ac√° es estudiar los que sirven para computadoras, pero ojo que sumar o multiplicar tambi√©n son algoritmos. Por ejemplo, el m√°s viejo de todos es el de Euclides para encontrar el m√°ximo com√∫n divisor.

Un algoritmo no tiene que dejarte elegir cosas al azar o pedirte que uses intuici√≥n. Si te dice ‚Äúagrega sal al gusto‚Äù no es algoritmo, porque no es preciso. Pero si te dice ‚Äúelige un n√∫mero entre 1 y 6 con la misma probabilidad‚Äù, ah√≠ s√≠, porque est√° claro c√≥mo hacerlo (por ejemplo, tirando un dado).

## C√≥mo escribimos los programas

Para evitar confusiones, vamos a mostrar los algoritmos usando algo parecido a un lenguaje de programaci√≥n estructurado (como Pascal), pero sin atarnos a uno solo. As√≠ la idea queda clara sin perder tiempo en detalles.

Usamos espa√±ol mezclado con s√≠mbolos matem√°ticos para que sea simple. Algunos conceptos (como recursividad o punteros) los damos por conocidos.

## Notaci√≥n matem√°tica r√°pida

Aqu√≠ repasamos r√°pido la notaci√≥n matem√°tica que usaremos: l√≥gica booleana (verdadero/falso), teor√≠a de conjuntos (conjuntos, subconjuntos, uniones, etc.), n√∫meros enteros y reales, sumas, productos y cosas como factoriales y combinaciones.

Tambi√©n hablamos de eficiencia: cu√°nto tiempo y memoria usa un algoritmo, y c√≥mo medir su rendimiento con la famosa notaci√≥n O grande (ej: O(n), O(log n)).

## En resumen

- Algoritmo = instrucciones claras, sin ambig√ºedades ni decisiones a mano.
- Usamos notaci√≥n mixta (programaci√≥n y matem√°tica) para explicarlos.
- Repasamos lo b√°sico que necesit√°s para no perderte.
- Explicamos c√≥mo medir la eficiencia para saber si un algoritmo es bueno o malo.
# T√©cnicas de Demostraci√≥n para No Perderse

## T√©cnica 1: Demostraci√≥n por Contradicci√≥n (o ‚Äúla trampa‚Äù)

Cuando tienes un mont√≥n de algoritmos y no sabes cu√°l usar, lo que importa es entender bien sus propiedades matem√°ticas, como cu√°nto tardan en resolver el problema seg√∫n el tama√±o de la entrada. Para eso, a veces hay que hacer demostraciones, y una de las m√°s usadas es la de contradicci√≥n.

¬øC√≥mo funciona? Pues b√°sicamente quieres probar que una cosa es cierta, pero en vez de hacerlo directo, dices: ‚ÄúBueno, supongamos que no es verdad‚Äù. Y luego te pones a sacar consecuencias de esa idea hasta que llegas a una tonter√≠a que no puede ser. Eso prueba que la idea original no puede ser falsa, ergo es verdadera. 

Por ejemplo: quieres probar que hay infinitos n√∫meros primos. Pues empiezas diciendo ‚ÄúNo, s√≥lo hay unos pocos‚Äù. Multiplicas todos esos primos y le sumas uno, y resulta que ese nuevo n√∫mero no puede ser dividido por ninguno de esos primos. Eso es una contradicci√≥n, porque seg√∫n tu suposici√≥n deber√≠a ser divisible. Por tanto, hay infinitos primos.

---

## T√©cnica 2: Inducci√≥n matem√°tica (o ‚Äúel truco del domin√≥‚Äù)

Esta t√©cnica es la que m√°s se usa para demostrar cosas en algoritmia. La idea es sencilla: si pruebas que algo es cierto para un caso base (por ejemplo, n = 0), y luego pruebas que si es cierto para un n√∫mero cualquiera n, entonces tambi√©n lo es para n + 1, entonces ya tienes la cosa comprobada para todos los n√∫meros naturales.

Un ejemplo tonto es un algoritmo que calcula el cuadrado de un n√∫mero `n`. Pruebas para algunos valores y ves que funciona, pero ¬øc√≥mo demostrar que siempre funciona? Con inducci√≥n: pruebas que funciona para n=0 y luego, suponiendo que funciona para n-1, demuestras que funciona para n. As√≠ de simple.

**Ojo:** Hay que tener cuidado, porque a veces la inducci√≥n falla si no se hacen bien las bases. Hay un ejemplo cl√°sico con caballos donde el ‚Äútruco‚Äù falla porque no se cumple para pasar de 1 a 2 caballos.  

---

## Inducci√≥n matem√°tica generalizada (o ‚Äúcuando la simple no alcanza‚Äù)

A veces la inducci√≥n normal no es suficiente, y necesitas una versi√≥n m√°s brava. Por ejemplo, para probar que cualquier n√∫mero compuesto se puede descomponer en n√∫meros primos, no basta con asumir que funciona para `n-1`. Necesitas asumir que funciona para **todos** los n√∫meros menores que `n`. Esto se llama inducci√≥n generalizada y es m√°s poderosa para cosas m√°s complicadas.

---

**Resumen:**  
- Contradicci√≥n: Sup√≥n que no, y si sale algo rid√≠culo, entonces s√≠.  
- Inducci√≥n: Demuestra para el caso base y que el paso de n a n+1 funciona, y listo.  
- Inducci√≥n generalizada: Cuando necesitas suponer cosas m√°s grandes para probar lo que quieres.

---

Si te interesa ver ejemplos m√°s locos o el porqu√© de todo esto, √©chale un ojo a los detalles m√°s formales en la secci√≥n que sigue.

# Inducci√≥n Constructiva y Otros Chunches Matem√°ticos

## Inducci√≥n Constructiva
La inducci√≥n matem√°tica es como la herramienta ninja para demostrar cosas raras que aparecen de la nada, como sacar un conejo del sombrero. Sirve no solo para confirmar que una afirmaci√≥n es verdad, sino tambi√©n para entender mejor qu√© carajos significa realmente esa afirmaci√≥n y c√≥mo funciona. 

Con la inducci√≥n constructiva, puedes demostrar que algo medio vago es cierto y, de paso, descubrir las piezas que faltaban para que tenga sentido. Un ejemplo com√∫n es con la sucesi√≥n de Fibonacci, que usaremos para mostrar c√≥mo esta t√©cnica ayuda a analizar algoritmos.

---

## Recordatorios B√°sicos (para no perderse)

### L√≠mites
Cuando una funci√≥n se vuelve loca y crece hasta el infinito o se va para el lado opuesto (menos infinito), o simplemente no se decide y baila entre valores, decimos que est√° oscilando. Si esa danza est√° controlada (no se pasa de cierto l√≠mite), es oscilaci√≥n finita, si no, es oscilaci√≥n infinita.

### Series Sencillas
Una serie puede ser amigable y converger a un n√∫mero (suma finita), o volverse loca y divergir hacia el infinito, o andar dando vueltas sin decidir. Ejemplos cl√°sicos: series aritm√©ticas y geom√©tricas.

### Combinatoria B√°sica
Si tienes objetos bien distintos (como figuritas con nombres), la combinatoria se encarga de contar cu√°ntas formas hay para ordenarlos o combinarlos.

### Probabilidad Elemental
Imagina que tienes n cosas etiquetadas (a, b, c...), la probabilidad estudia cu√°ntas maneras hay de ordenar esas cosas o sacar eventos al azar.

---

## Algoritmia Elemental

### ¬øQu√© es un algoritmo?
Un algoritmo es como la receta para hacer cualquier cosa paso a paso, ya sea para programar, matem√°ticas o hasta para armar un s√°ndwich.

### Eficiencia de Algoritmos
La eficiencia mide qu√© tan bien un algoritmo usa los recursos (tiempo, memoria) para resolver su problema. Un buen algoritmo no solo funciona, sino que lo hace r√°pido y sin gastar mucha chamba computacional.

### An√°lisis: Caso Peor y Caso Medio
- **Caso Peor:** cuando la cosa se pone dif√≠cil y el algoritmo se tarda lo m√°ximo posible (usamos la notaci√≥n O grande).
- **Caso Medio:** el promedio que tarda el algoritmo considerando entradas random (se representa con Œò).

### Operaci√≥n Elemental
Es la tarea m√°s b√°sica que hace un algoritmo y que toma tiempo fijo. Contar estas operaciones nos ayuda a medir qu√© tan pesado es el algoritmo.

### ¬øPor qu√© buscar eficiencia?
Porque la compu no es m√°gica. Si no usas bien los recursos, tu programa va a ser un desastre, lento y poco √∫til, sobre todo con datos gigantescos.

---

## Notaci√≥n Asint√≥tica

Esta notaci√≥n es para entender c√≥mo se comportan los algoritmos cuando el tama√±o del problema crece hasta la locura. Aunque a veces no sirve para casos chiquitos, en general te dice qu√© algoritmo es mejor cuando la cosa se pone seria.

---

**Resumen:**  
Si quieres sobrevivir en programaci√≥n, tienes que entender estas t√©cnicas y conceptos b√°sicos. Sirven para demostrar que las cosas funcionan y para elegir el camino r√°pido y limpio cuando programas.

# Notaci√≥n Big-O y An√°lisis de Algoritmos (Versi√≥n Desenchufada)

## ¬øQu√© carajo es esto del "orden de"?

La notaci√≥n Big-O es la forma chida de decir ‚Äúm√°s o menos cu√°nto se tarda algo sin complicarnos‚Äù. Se usa para medir c√≥mo crece la dificultad (tiempo, memoria) de un algoritmo con el tama√±o del problema. Por ejemplo, cuando dicen que un algoritmo es O(n¬≥), quiere decir que, a medida que n crece, el tiempo crece m√°s o menos como n¬≥.

Ojo, no siempre ver√°s la notaci√≥n igual: algunos ponen O(f(n)) y otros dicen "n es del orden de f(n)". No te calientes, es lo mismo pero con diferente estilo. A veces hasta meten funciones raras, hasta negativas o con detalles que no importan para lo grande.

## Notaci√≥n asint√≥tica para los que quieren m√°s l√≠o

Si el peor caso tarda menos de cierta funci√≥n multiplicada por una constante, decimos que est√° en O(f(n)). Si en cambio tarda al menos eso (un piso), est√° en Œ©(f(n)). Y si est√° en ambos lados, decimos que es Œò(f(n)). B√°sicamente, O es el techo, Œ© el piso, y Œò el rango exacto.

Por ejemplo, ordenar con inserci√≥n es O(n¬≤) en el peor caso, pero en muchos casos va m√°s r√°pido (como cuando la lista ya est√° casi ordenada). As√≠ que un algoritmo puede tener tiempos muy diferentes dependiendo de la situaci√≥n.

## Varias variables, varios rollos

A veces el tiempo no depende solo de un n√∫mero, sino de dos o m√°s, como en grafos que dependen de nodos y aristas. En ese caso usamos una notaci√≥n Big-O multidimensional, tipo O(f(m,n)).

## C√≥mo manejar la notaci√≥n sin perder la cabeza

Cuando sumamos tiempos de varias partes de un algoritmo, no hay que andar con mucha paranoia: O(f(n)) + O(g(n)) es lo mismo que O(max(f(n), g(n))). O sea, el tiempo total es del que crece m√°s r√°pido.

## An√°lisis de algoritmos: el punto real del asunto

El objetivo es dise√±ar algoritmos que sean r√°pidos y eficientes. Cuando tienes varios m√©todos para un problema, toca decidir cu√°l usar. Esto no es magia: se basa en experiencia, intuici√≥n y, claro, en analizar tiempos con t√©cnicas como resolver ecuaciones de recurrencia o entender estructuras de control (bucles, recursi√≥n, etc.).

## An√°lisis r√°pido de bucles y cosas raras

- Los bucles `for` suelen ser f√°ciles: si algo se repite m veces y cada vez cuesta t, el total es m*t.
- Pero ojo, a veces el control del bucle suma tiempo que no ves a simple vista.
- Bucles `while` o `repeat` son un poco m√°s jodidos, porque no sabes cu√°ntas vueltas van a dar. Se analiza usando funciones que bajan cada vez y garantizan que el bucle termina.
- Las llamadas recursivas se analizan con ecuaciones de recurrencia. Algunos ejemplos, como Fibonacci recursivo, crecen muy r√°pido (exponencialmente).

## Usar un ‚Äúbar√≥metro‚Äù

Para no marearse con todos los detalles, se escoge una instrucci√≥n que se ejecuta m√°s que todas (el ‚Äúbar√≥metro‚Äù). El tiempo del algoritmo es del orden de las veces que se ejecuta esa instrucci√≥n. As√≠ se simplifica el an√°lisis sin perder la idea principal.

## Ejemplo: inserci√≥n

El peor caso de ordenaci√≥n por inserci√≥n pasa cuando la lista est√° ordenada al rev√©s. Ah√≠, el bucle que mueve los elementos se ejecuta como n¬≤/2 veces, o sea, O(n¬≤). Pero si la lista ya est√° casi ordenada, va mucho m√°s r√°pido.

---

#  Bimestre 2 ‚Äì Algoritmos: Divide y Vencer√°s, B√∫squeda, Ordenaci√≥n y Grafos

## üîπ Divide y Vencer√°s

Aprendimos la estrategia de ‚Äúdivide y vencer√°s‚Äù, que consiste en dividir un problema en partes peque√±as, resolverlas por separado y luego combinarlas. Se vio con un ejemplo de multiplicaci√≥n: 981 √ó 1234.

En lugar de multiplicar directamente, se separan los n√∫meros:

- 981 ‚Üí w = 09, x = 81
- 1234 ‚Üí y = 12, z = 34

Se calculan:
- `p = w * y = 108`
- `q = x * z = 2754`
- `r = (w + x) * (y + z) = 90 * 46 = 4140`

Y luego:
> Resultado = 10‚Å¥ * p + 10¬≤ * (r ‚àí p ‚àí q) + q

Este m√©todo reduce el n√∫mero de multiplicaciones necesarias y se basa en una t√©cnica algor√≠tmica eficiente.

---

```Java
package pseudoaleatorios;
import java.util.Scanner;

public class Pseudoaleatorios {
    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);

        System.out.print("Cantidad de n√∫meros a generar: ");
        int cantidad = scanner.nextInt();

        System.out.print("Ingrese la semilla (X0): ");
        long x = scanner.nextLong();

        // Par√°metros cl√°sicos para el algoritmo
        final long a = 1664525;     // multiplicador
        final long c = 1013904223;  // incremento
        final long m = (long) Math.pow(2, 32);  // m√≥dulo

        System.out.println("N√∫meros pseudoaleatorios generados:");
        for (int i = 0; i < cantidad; i++) {
            x = (a * x + c) % m;
            System.out.println(x);
        }

        scanner.close();
    }
}

```
![Pseudonumeros](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/Pseudonumeros.png)

## üîπ B√∫squeda Binaria

Es una t√©cnica eficiente para buscar elementos en listas ordenadas. Reduce el espacio de b√∫squeda a la mitad en cada paso.

- Complejidad: O(log n)
- Mucho m√°s r√°pida que una b√∫squeda lineal si los datos est√°n ordenados.

---
```Java
package busquedabinaria;
import java.util.Arrays;
import java.util.Random;
import java.util.Scanner;

public class BusquedaBinaria {

    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);
        Random random = new Random();

        System.out.print("¬øCu√°ntos n√∫meros aleatorios deseas generar? ");
        int n = scanner.nextInt();

        int[] numeros = new int[n];
        for (int i = 0; i < n; i++) {
            numeros[i] = random.nextInt(100); // N√∫meros entre 0 y 99
        }

        // Ordenamos el arreglo antes de buscar
        Arrays.sort(numeros);
        System.out.println("Arreglo ordenado:");
        System.out.println(Arrays.toString(numeros));

        System.out.print("¬øQu√© n√∫mero deseas buscar? ");
        int objetivo = scanner.nextInt();

        // Elegir m√©todo de b√∫squeda binaria
        int resultado = busquedaBinariaIterativa(numeros, objetivo);
        // int resultado = busquedaBinariaRecursiva(numeros, 0, numeros.length - 1, objetivo);

        if (resultado != -1) {
            System.out.println("N√∫mero encontrado en la posici√≥n: " + resultado);
        } else {
            System.out.println("N√∫mero no encontrado.");
        }

        scanner.close();
    }

    // B√∫squeda binaria iterativa
    public static int busquedaBinariaIterativa(int[] arr, int objetivo) {
        int izquierda = 0;
        int derecha = arr.length - 1;

        while (izquierda <= derecha) {
            int medio = (izquierda + derecha) / 2;

            if (arr[medio] == objetivo) {
                return medio;
            } else if (arr[medio] < objetivo) {
                izquierda = medio + 1;
            } else {
                derecha = medio - 1;
            }
        }

        return -1;
    }

    // B√∫squeda binaria recursiva (opcional)
    public static int busquedaBinariaRecursiva(int[] arr, int izquierda, int derecha, int objetivo) {
        if (izquierda > derecha) {
            return -1;
        }

        int medio = (izquierda + derecha) / 2;

        if (arr[medio] == objetivo) {
            return medio;
        } else if (arr[medio] < objetivo) {
            return busquedaBinariaRecursiva(arr, medio + 1, derecha, objetivo);
        } else {
            return busquedaBinariaRecursiva(arr, izquierda, medio - 1, objetivo);
        }
    }
}

```
![Busqueda Binaria](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/BusquedaBinaria.png)

## üîπ Ordenaci√≥n ‚Äì Quicksort

El algoritmo **quicksort** selecciona un pivote y divide el arreglo en elementos menores y mayores. Luego aplica recursivamente la misma idea.

- Eficiente en promedio
- Amplio uso en programaci√≥n

---
```Java
package busquedabinaria;
import java.util.Arrays;
import java.util.Random;
import java.util.Scanner;

public class QuickSortEjemplo {

    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);
        Random random = new Random();

        System.out.print("¬øCu√°ntos n√∫meros aleatorios deseas generar? ");
        int n = scanner.nextInt();

        int[] arreglo = new int[n];
        for (int i = 0; i < n; i++) {
            arreglo[i] = random.nextInt(100); // N√∫meros entre 0 y 99
        }

        System.out.println("Arreglo original:");
        System.out.println(Arrays.toString(arreglo));

        quicksort(arreglo, 0, arreglo.length - 1);

        System.out.println("Arreglo ordenado con Quicksort:");
        System.out.println(Arrays.toString(arreglo));

        scanner.close();
    }

    // Implementaci√≥n de Quicksort
    public static void quicksort(int[] arr, int izquierda, int derecha) {
        if (izquierda < derecha) {
            int indicePivote = particion(arr, izquierda, derecha);

            quicksort(arr, izquierda, indicePivote - 1);  // Subarreglo izquierdo
            quicksort(arr, indicePivote + 1, derecha);    // Subarreglo derecho
        }
    }

    // Funci√≥n de partici√≥n (usa el √∫ltimo elemento como pivote)
    public static int particion(int[] arr, int izquierda, int derecha) {
        int pivote = arr[derecha];
        int i = izquierda - 1;

        for (int j = izquierda; j < derecha; j++) {
            if (arr[j] <= pivote) {
                i++;
                intercambiar(arr, i, j);
            }
        }

        intercambiar(arr, i + 1, derecha);
        return i + 1;
    }

    // M√©todo auxiliar para intercambiar elementos
    public static void intercambiar(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
}

```
![QuickSort](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/QuickSort.png)
## üîπ Algoritmos Voraces (Greedy)

Son algoritmos que toman decisiones paso a paso, eligiendo la opci√≥n m√°s conveniente en cada momento.

**Ejemplo pr√°ctico:** dar cambio con el menor n√∫mero de monedas posibles.

**Ventajas:**
- Sencillos de implementar
- Eficientes para muchos casos

**Desventajas:**
- No garantizan la mejor soluci√≥n en todos los casos

---
```Java
package mochilavoraz;
import java.util.*;

class Objeto {
    int valor, peso;
    double ratio;

    public Objeto(int valor, int peso) {
        this.valor = valor;
        this.peso = peso;
        this.ratio = (double) valor / peso;
    }
}

public class MochilaVoraz {

    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);

        System.out.print("N√∫mero de objetos: ");
        int n = scanner.nextInt();

        Objeto[] objetos = new Objeto[n];

        for (int i = 0; i < n; i++) {
            System.out.print("Valor del objeto " + (i + 1) + ": ");
            int valor = scanner.nextInt();
            System.out.print("Peso del objeto " + (i + 1) + ": ");
            int peso = scanner.nextInt();
            objetos[i] = new Objeto(valor, peso);
        }

        System.out.print("Capacidad de la mochila: ");
        int capacidad = scanner.nextInt();

        double maxValor = mochilaFraccionaria(objetos, capacidad);

        System.out.printf("Valor m√°ximo en la mochila: %.2f\n", maxValor);

        scanner.close();
    }

    public static double mochilaFraccionaria(Objeto[] objetos, int capacidad) {
        Arrays.sort(objetos, (a, b) -> Double.compare(b.ratio, a.ratio)); // Ordenar por valor/peso descendente

        double valorTotal = 0.0;

        for (Objeto obj : objetos) {
            if (capacidad == 0) break;

            if (obj.peso <= capacidad) {
                valorTotal += obj.valor;
                capacidad -= obj.peso;
            } else {
                valorTotal += obj.ratio * capacidad;
                capacidad = 0;
            }
        }

        return valorTotal;
    }
}

```
![Mochila Voraz](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/MochilaVoraz.png)
## üîπ Grafos y √Årbol de Recubrimiento M√≠nimo (MST)

Un **grafo** es un conjunto de nodos (v√©rtices) conectados por enlaces (aristas).

El **√°rbol de recubrimiento m√≠nimo** conecta todos los nodos con el menor costo total, sin ciclos. Se usa en redes el√©ctricas, transporte, etc.

El **algoritmo de Kruskal** es uno de los m√°s usados para encontrar este √°rbol, seleccionando siempre la arista m√°s barata sin formar ciclos.

---
### Grafos:
![Grafos](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/grafos.PNG)

### Arbol de recubrimiento minimo
![Arbol de recubrimiento minimo](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/Arbol%2Bde%2Bcubrimiento%2Bm%C3%ADnimo.jpg)

### Algoritmo de Kurskal
![Algoritmo de Kurskal](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/AlgoritmoDeKurskal.jpg)
# üìò Estrategias Bajo Incertidumbre y Algoritmos Probabil√≠sticos

## üî∏ Problema del Tesoro y el Drag√≥n

Un tesoro con `x` lingotes est√° escondido en A o B. Se desconoce su ubicaci√≥n exacta. Viajar desde el punto de partida (O) toma 5 d√≠as y cada noche un drag√≥n roba `y` lingotes.

Opciones:

1. Esperar 4 d√≠as para saber con certeza la ubicaci√≥n.
2. Pagarle a un elfo `3y` lingotes para saberla de inmediato.
3. Elegir al azar (por ejemplo, lanzar una moneda).

**Valor esperado con opci√≥n aleatoria:**

- Acertar (50%): p√©rdida de `5y` ‚Üí ganancia: `x ‚àí 5y`
- Fallar (50%): p√©rdida de `10y` ‚Üí ganancia: `x ‚àí 10y`

> Esperanza matem√°tica:  
> `E[ganancia] = 0.5(x ‚àí 5y) + 0.5(x ‚àí 10y) = x ‚àí 7.5y`

Este enfoque usa **estrategias probabil√≠sticas** para tomar decisiones basadas en el riesgo y beneficio esperado.

---

## üî∏ Algoritmos Probabil√≠sticos

- No garantizan siempre el mismo resultado.
- Usan variables aleatorias para tomar decisiones.
- Son √∫tiles cuando obtener informaci√≥n exacta es costoso o incierto.

**Ventajas:**
- Flexibles y r√°pidos
- Buen rendimiento pr√°ctico

**Desventajas:**
- Pueden fallar o no dar siempre la mejor soluci√≥n
- Requieren an√°lisis m√°s avanzado (probabilidades, esperanza matem√°tica)

---
![Algoritmos y probabilidades](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/AlgoritmosYprobabilidades.png)

## üî∏ N√∫meros Pseudoaleatorios

Los **n√∫meros pseudoaleatorios** son generados por algoritmos (como el generador lineal congruencial) y se comportan como si fueran aleatorios.

> F√≥rmula: `X‚Çô‚Çä‚ÇÅ = (a * X‚Çô + c) mod m`

- Se usan en simulaciones, pruebas, juegos, etc.

---
### Ejemplo:
```Java
package pseudoaleatorios;
import java.util.Scanner;

public class Pseudoaleatorios {
    public static void main(String[] args) {
        Scanner scanner = new Scanner(System.in);

        System.out.print("Cantidad de n√∫meros a generar: ");
        int cantidad = scanner.nextInt();

        System.out.print("Ingrese la semilla (X0): ");
        long x = scanner.nextLong();

        // Par√°metros cl√°sicos para el algoritmo
        final long a = 1664525;     // multiplicador
        final long c = 1013904223;  // incremento
        final long m = (long) Math.pow(2, 32);  // m√≥dulo

        System.out.println("N√∫meros pseudoaleatorios generados:");
        for (int i = 0; i < cantidad; i++) {
            x = (a * x + c) % m;
            System.out.println(x);
        }

        scanner.close();
    }
}

```
![Pseudonumeros](https://raw.githubusercontent.com/andres726127/An-lisis-de-Algoritmos/refs/heads/main/carpeta_nueva/Pseudonumeros.png)

## üî∏ Tiempo de Ejecuci√≥n

- **Tiempo promedio:** en algoritmos deterministas (seg√∫n todas las entradas).
- **Tiempo esperado:** en algoritmos probabil√≠sticos (seg√∫n decisiones aleatorias).
- **Tiempo esperado en el peor caso:** combinaci√≥n de los dos anteriores para situaciones m√°s conservadoras.

---

## üî∏ Algoritmos Deterministas vs Probabil√≠sticos

| Determinista        | Probabil√≠stico              |
|---------------------|-----------------------------|
| Siempre da el mismo resultado | Puede dar diferentes resultados |
| An√°lisis m√°s estructurado     | Requiere an√°lisis probabil√≠stico |
| √ötil para problemas conocidos | √ötil en situaciones inciertas   |

---


